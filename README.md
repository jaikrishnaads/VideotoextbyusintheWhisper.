# ğŸ“¦ Batch Video Transcriber (Offline AI)

A simple **offline batch video transcription tool** built with **Streamlit** and **OpenAI Whisper**.
Upload multiple video files, let the AI transcribe them **locally**, and download all transcripts as a single ZIP file.

No cloud APIs.
No internet dependency *after model download*.
No nonsense.

---

## âœ¨ Features

* ğŸ¥ Upload **multiple videos at once**
* ğŸ§  Uses **Whisper (base model)** for speech-to-text
* ğŸ“´ Runs **fully offline** after setup
* ğŸ“„ Generates **separate `.txt` transcript** for each video
* ğŸ“¦ Downloads all transcripts as a **ZIP file**
* ğŸ“Š Progress bar for batch processing
* ğŸ§¼ Automatic cleanup of temporary files

---

## ğŸ§  How It Works (Concept)

1. User uploads multiple video files
2. Each video is temporarily stored
3. Audio is extracted internally by Whisper
4. Speech is transcribed into text
5. Each transcript is saved as a `.txt`
6. All text files are packed into a ZIP for download

Everything runs **locally on your machine**.

---

## ğŸ›  Tech Stack

* **Python**
* **Streamlit** â€“ UI
* **OpenAI Whisper** â€“ Offline speech recognition
* **FFmpeg** â€“ Audio extraction (required by Whisper)

---

## ğŸ“¦ Supported Video Formats

* `.mp4`
* `.mkv`
* `.mov`
* `.avi`

---

## ğŸš€ Installation & Setup

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/jaikrishnaads/VideotoextbyusintheWhisper..git
cd batch-video-transcriber
```

### 2ï¸âƒ£ Create a Virtual Environment (recommended)

```bash
python -m venv venv
source venv/bin/activate      # Linux / macOS
venv\Scripts\activate         # Windows
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install streamlit openai-whisper
```

### 4ï¸âƒ£ Install FFmpeg (Required)

Whisper **will not work without FFmpeg**.

* **Windows**:
  Download from [https://ffmpeg.org](https://ffmpeg.org)
  Add `ffmpeg/bin` to PATH

* **Linux**:

```bash
sudo apt install ffmpeg
```

* **macOS**:

```bash
brew install ffmpeg
```

---

## â–¶ï¸ Run the App

```bash
streamlit run app.py
```

Open the shown local URL in your browser.

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ app.py              # Main Streamlit app
â”œâ”€â”€ README.md           # Documentation
â””â”€â”€ requirements.txt    # (optional)
```

---

## âš ï¸ Notes & Limitations

* First run will download the Whisper model (~140MB)
* Processing speed depends on:

  * CPU power
  * Video length
  * Audio clarity
* Long videos may take time (this is offline AI, not cloud magic)

---

## ğŸ”’ Privacy

* All processing is done **locally**
* No data is uploaded anywhere
* Videos and audio are deleted after transcription

Your data stays yours.

---

## ğŸŒ± Future Improvements

* Language selection
* Speaker diarization
* Export to PDF / SRT
* Desktop app version
* Android APK wrapper

---

## ğŸ“œ License

This project is open-source and free to use for learning and personal projects.
Check Whisperâ€™s license for commercial usage.

---

## ğŸ§ª Built For

Vibe coders.
Offline enjoyers.
People who hate API keys.

---

If you want, next we can:

* Convert this into a **desktop EXE**
* Wrap it into an **Android APK**
* Add a **local transcript library**
* Or rewrite this in **pure offline mobile logic**

This README already smells like a real project.
